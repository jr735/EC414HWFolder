{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EC414_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jr735/EC414HWFolder/blob/master/EC414_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDnayQkt-Vw5"
      },
      "source": [
        "# Homework 2: Linear Regression\r\n",
        "by Yousif Khaireddin and Sadie Allen\r\n",
        "\r\n",
        "**Due date**: February 17, Wednesday by 11:59pm\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbDOBnxLIf4N"
      },
      "source": [
        "## **Question 1:** Ridge regression derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74JIPHp5JiGb"
      },
      "source": [
        "**Throughout the following, please adhere to the following definitions**\r\n",
        "\r\n",
        "$\r\n",
        "n = number\\ of\\ samples \\\\\r\n",
        "d = number\\ of\\ features \\\\\r\n",
        "$\r\n",
        "\r\n",
        "$\r\n",
        "X = samples \\in \\mathcal{R}^{n x d}\\\\\r\n",
        "y = labels \\in \\mathcal{R}^n \\\\\r\n",
        "w = weight\\ matrix \\in \\mathcal{R}^d\r\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IzsMMniH2z4"
      },
      "source": [
        "In class, we have derived the closed form solution for OLS Regression. \r\n",
        "\r\n",
        "$\r\n",
        "loss = \\sum_{i=0}^{n}||y_i - \\sum_{j=0}^{d}x_{ij}w_j||^2 = (\\textbf{y} - \\textbf{Xw})^T (\\textbf{y} - \\textbf{Xw})\r\n",
        "$\r\n",
        "<br>\r\n",
        "\r\n",
        "\r\n",
        "The optimal value for the parameter $\\textbf{w}$ is given by\r\n",
        "\r\n",
        "$\r\n",
        "\\textbf{w*} = (\\textbf{X}^T \\textbf{X})^{-1}\\ \\textbf{X}^T \\textbf{y} \\\\\r\n",
        "$\r\n",
        "\r\n",
        "To control the variance of the parameters and avoid them growing to infinity and help with overfitting, ridge regression tries to regularize the loss function using w, shown below:\r\n",
        "<br><br>\r\n",
        "\r\n",
        "\r\n",
        "$\r\n",
        "loss = (\\textbf{y} - \\textbf{Xw})^T (\\textbf{y} - \\textbf{Xw} ) + \\lambda ||\\textbf{w}||^2_2\r\n",
        "$\r\n",
        "<br><br>\r\n",
        "\r\n",
        "\r\n",
        "The degree to which this regularization impacts the loss function is controlled by the $\\lambda$ parameter. This is a hyper-parameter which must be tuned using a validation set.\r\n",
        "\r\n",
        "<br>\r\n",
        "\r\n",
        "\r\n",
        "Derive the closed form solution of ridge regression using the same workflow used in class to derive OLS.\r\n",
        "\r\n",
        "**Hint:** You are trying to minimize the loss w.r.t. to $w$   \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20PBq4H_Anp9"
      },
      "source": [
        "**Answer:**\r\n",
        "Goal is to minimize $$\\sum_{i=1}^{n} (y_{i}-w^{T}x_{i})^2 +\\lambda w^{T}w$$\r\n",
        "Easy way to do this is to vectorize y and make the $$x_{i}$$s in the sum a matrix X so that we can drop the summation notation:\r\n",
        "Ridge sol'n: $$(y-Xw)^2 +\\lambda w^{T}w$$\r\n",
        "Take the derivative with respect to w and set equal to zero:\r\n",
        "$$\\frac{d}{dw} [(y-Xw)^2 +\\lambda w^{T}w]= 2(X^{T}X)w-2X^{T}y+2\\lambda w=0$$\r\n",
        "$$2(X^{T}X)w+2\\lambda w=2X^{T}y$$\r\n",
        "$$(X^{T}X+\\lambda I)w=X^{T}y$$\r\n",
        "And finally, this minimizes the soln: $$w=(X^{T}X+\\lambda I)^{-1}X^{T}y$$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv8p6dTD1Xtr"
      },
      "source": [
        "## **Question 2:**  Relationship between Lasso Regression and Maximum a posteriori estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDPgHMK1e3c"
      },
      "source": [
        "As we have previously discussed in class, in linear regression, we can consider $y$ to be the product of the weight vector with the sample with some added noise factor. \r\n",
        "\r\n",
        "$ y = w^Tx + \\mathcal{N} (0, \\sigma^2) $\r\n",
        "\r\n",
        "So, each $y_i$ is distributed according to a gaussian distribution governed by the noise, and mean-shifted by $w^Tx$\r\n",
        "\r\n",
        "$y \\sim \\mathcal{N} (w^Tx, \\sigma^2)$\r\n",
        "\r\n",
        "$p(y|x, w) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\sum_{i=1}^{n} \\frac{-(y_i - x_i^Tw)^2}{2\\sigma^2}} $\r\n",
        "<br><br>\r\n",
        "\r\n",
        "\r\n",
        "Additionally, assume the prior of the model is Laplacian whose coefficients are iid with zero mean and scale parameter $b$.\r\n",
        "\r\n",
        "$p(w|\\mu, b) = \\frac{1}{2b}e^{\\frac{-||w-\\mu||_1}{b}}$\r\n",
        "<br>\r\n",
        "\r\n",
        "\r\n",
        "Show that the formula for LASSO linear regression can be derived via MAP estimation with a Laplace prior.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDqtxuABUwXn"
      },
      "source": [
        "**Answer** \r\n",
        "MAP estimator for a gaussian is $$w_{MAP}= argmax_{w} P(y|w,x,\\sigma^2)P(w)$$\r\n",
        "Plugging in the above Gaussian distribution and Laplacian prior gives:\r\n",
        "$$w_{MAP}= argmax_{w}  \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{\\sum_{i=1}^{n} (-\\frac{(y_{i}-x_{i}^{T}w)^2} {2\\sigma^2})}*\\frac{1}{2b} e^{-\\frac{||w-\\mu||_{1}}{b}}$$\r\n",
        "$$w_{MAP}= argmax_{w}  \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{\\sum_{i=1}^{n} (-\\frac{(y_{i}-x_{i}^{T}w)^2} {2\\sigma^2})}*\\prod_{j=1}^p \\frac{1}{2b} e^{-\\frac{||w-\\mu||_{1}}{b}}$$\r\n",
        "Take the natural log and ignore some constants: $$ argmax_{w} \\sum_{i=1}^{n} (-\\frac{(y_{i}-x_{i}^{T}w)^2} {2\\sigma^2})-\\sum_{j=1}^p \\lambda ||w-\\mu||$$ where $\\lambda$ is just $\\frac{1}{b}$ and is the scale parameter usually seen in the lasso formula.\r\n",
        "Take argmin of the negative expression and ignore some more constants: $$ argmin_{w} \\sum_{i=1}^{n} (\\frac{(y_{i}-x_{i}^{T}w)^2} {2\\sigma^2})+\\sum_{j=1}^p \\lambda ||w-\\mu||$$\r\n",
        "And then if you make $\\lambda$ to be $\\frac{2\\sigma^2}{b}$ this basically becomes: $$ argmin_{w} \\sum_{i=1}^{n} (y_{i}-x_{i}^{T}w^2)+ \\lambda||w||_1$$ which is the formula for LASSO.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5yndLcyOTN"
      },
      "source": [
        "## **Question 3:** Linear Regression Implementation (OLS, Ridge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZz-JWJlyY3d"
      },
      "source": [
        "Throughout this question we will be concerned with implementing Linear regression and Ridge regression and verifying our results against sklearn's inbuilt functions. \r\n",
        "\r\n",
        "To do this, we will be using a very simple and small dataset containing 50 samples and only 1 feature.  \r\n",
        "\r\n",
        "This will enable us to plot and visualize everything along the way. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWXoz_MJi6X5"
      },
      "source": [
        "### Data processing and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ms6c0qWHWal5",
        "outputId": "6722b9cd-1933-41e7-8b01-548c12e35a3a"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "\r\n",
        "X, y, coefficients = make_regression(\r\n",
        "    n_samples=50,\r\n",
        "    n_features=1,\r\n",
        "    n_informative=1,\r\n",
        "    n_targets=1,\r\n",
        "    noise=5,\r\n",
        "    coef=True,\r\n",
        "    random_state=10\r\n",
        ")\r\n",
        "\r\n",
        "print(\"X shape:\", X.shape, sep='\\t')\r\n",
        "print(\"y shape:\", y.shape, sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:\t(50, 1)\n",
            "y shape:\t(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmkYehMiaPlV"
      },
      "source": [
        "Create a scatter plot of all datapoints to see our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mam6xKvXZ6FP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0ff70b52-cb32-4574-db09-5eb8bca19dbd"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "plt.scatter(X,y,marker='o')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f180a98bb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q59lV2qy1Hnu"
      },
      "source": [
        "Attach a vector of ones onto **X** to account for the bias value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FZ5WfvM1HQI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d3c30f3b-2928-4dd6-f97a-80e3f24ae57a"
      },
      "source": [
        "ones = np.ones((50,1))\r\n",
        "print(ones.shape)\r\n",
        "X = np.hstack((X,ones))\r\n",
        "\r\n",
        "\r\n",
        "print(\"X shape:\", X.shape, sep='\\t')\r\n",
        "print(\"y shape:\", y.shape, sep='\\t')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1)\n",
            "X shape:\t(50, 2)\n",
            "y shape:\t(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0iCfv7A1V4u"
      },
      "source": [
        "Using **train_test_split** from sklearn, seperate the data using a 60, 20, 20 split.\r\n",
        "\r\n",
        "* Make sure to suffle the dataset using a **random_state** of 42\r\n",
        "\r\n",
        "**Hint:** \r\n",
        "\r\n",
        "* This can be done easily with 2 calls to **train_test_split**. \r\n",
        "\r\n",
        "* The first call will split the data into train/test, and the second will split the train data into train/val\r\n",
        "\r\n",
        "**Note:** \r\n",
        "\r\n",
        "Though we will have no use for the validation set in this question since we are merely concerned with creating all the required implementations at this time, it will be vital in the next question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDIxO-VZz5-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1a651ae-6b03-4d3c-9c25-7fa62ebdb538"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size=0.2,random_state=42)\r\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain,test_size=0.25,random_state=42)\r\n",
        "\r\n",
        "print(\"xtrain shape:\", xtrain.shape, sep='\\t')\r\n",
        "print(\"xval shape:\", xval.shape, sep='\\t')\r\n",
        "print(\"xtest shape:\", xtest.shape, '\\n', sep='\\t')\r\n",
        "\r\n",
        "print(\"ytrain shape:\", ytrain.shape, sep='\\t')\r\n",
        "print(\"yval shape:\", yval.shape, sep='\\t')\r\n",
        "print(\"ytest shape:\", ytest.shape, sep='\\t')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain shape:\t(30, 2)\n",
            "xval shape:\t(10, 2)\n",
            "xtest shape:\t(10, 2)\t\n",
            "\n",
            "ytrain shape:\t(30,)\n",
            "yval shape:\t(10,)\n",
            "ytest shape:\t(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlm5k9gDf4bh"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vN_svN5hr1f"
      },
      "source": [
        "Define a function *get_loss* that takes the inputs X, y, and W and calculates the loss required (MSE). Its skeleton is shown below.\r\n",
        "\r\n",
        "For full credit, create a vectorized implementation (no for loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF41wAsRhrOG"
      },
      "source": [
        "def get_loss(X, y, W):\r\n",
        "    term_1=y-X.dot(W)\r\n",
        "    term_2=term_1.transpose()\r\n",
        "    loss =term_2.dot(term_1)\r\n",
        "    return loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5CtrKUday0Q"
      },
      "source": [
        "Using the derivation done in class, implement the closed form solution for ordinary least squares.\r\n",
        "\r\n",
        "Do this by defining a function *OLS* that takes the inputs $\\mathbf{X}$ and $\\mathbf{y}$ and returns $\\mathbf{w}$. Its skeleton is shown below.\r\n",
        "\r\n",
        "For full credit, do not use the inverse function\r\n",
        "\r\n",
        "**Hint:** you may want to look into *numpy.linalg.solve* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UBVsYH_0xWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3f3461db-dfb3-4fad-fe85-456e38ed5b61"
      },
      "source": [
        "def OLS(X, y):\r\n",
        "    A=X.transpose().dot(X)\r\n",
        "    b=X.transpose().dot(y)\r\n",
        "    W=np.linalg.solve(A,b)\r\n",
        "    return W\r\n",
        "\r\n",
        "W_ols = OLS(xtrain, ytrain)\r\n",
        "print(\"W_ols:\", W_ols)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_ols: [ 1.01054998e+02 -8.83448668e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVamkAfJa932"
      },
      "source": [
        "Create the following plots:\r\n",
        "* a scatter plot of the training data overlayed by the OLS solution\r\n",
        "* a scatter plot of the testing data overlayed by the OLS solution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW7QTvQQ1-T0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "c471aa1a-14b2-4106-e1c4-de672fcdf6ca"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "plt.scatter(xtrain[:,0],ytrain,marker='o')\r\n",
        "plt.plot(xtrain, W_ols[0]*xtrain+W_ols[1], 'b')\r\n",
        "plt.scatter(xtest[:,0],ytest,marker='+')\r\n",
        "plt.plot(xtest,W_ols[0]*xtest+W_ols[1],'r')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1809fa3668>,\n",
              " <matplotlib.lines.Line2D at 0x7f1809fa3f60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cp9D7DSbnbF"
      },
      "source": [
        "Compute training loss and testing loss using the *get_loss* function you have previously defined "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0iNW6w93nfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "66bc2de6-8623-4f09-9eca-763ab8b84c7d"
      },
      "source": [
        "loss_train = get_loss(xtrain,ytrain,W_ols)\r\n",
        "loss_test = get_loss(xtest,ytest,W_ols)\r\n",
        "\r\n",
        "print(\"Training Loss:\", loss_train)\r\n",
        "print(\"Testing Loss:\", loss_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 931.7441303764379\n",
            "Testing Loss: 428.51876889248445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhLpnDhgAjf"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H00sDTfPbwDq"
      },
      "source": [
        "Define a function *get_ridge_loss* that takes the inputs X, y, W, and $\\lambda$ and calculates the loss required (MSE with L2 regularization). \r\n",
        "\r\n",
        "Its skeleton is shown below.\r\n",
        "\r\n",
        "For full credit, create a vectorized implementation (no for loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AelQiKx0chaT"
      },
      "source": [
        "def get_ridge_loss(X, y, W, lmda):\r\n",
        "    term_1=y-X.dot(W)\r\n",
        "    term_2=term_1.transpose()\r\n",
        "    reg=lmda*W.transpose().dot(W)\r\n",
        "    loss =term_2.dot(term_1)+reg\r\n",
        "    return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FXBpy1idcp5"
      },
      "source": [
        "Using your derivation from question 1, implement the closed form solution for ridge regression.\r\n",
        "\r\n",
        "Do this by defining a function *ridge* that takes the inputs $\\mathbf{X}$, $\\mathbf{y}$, and $\\lambda$ and returns $\\mathbf{w}$. Its skeleton is shown below.\r\n",
        "\r\n",
        "For full credit, do not use the inverse function\r\n",
        "\r\n",
        "For now, we will set $\\lambda = 0.1$. \r\n",
        "This performance will not be optimal, but we will worry about this later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQPFvmv9cuv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b82f1d5f-d0a1-4920-9aaa-762700e8a0ff"
      },
      "source": [
        "def ridge(X, y, lmda):\r\n",
        "    b=X.transpose().dot(y)\r\n",
        "    n=len(b)\r\n",
        "    lmda_mat=lmda*np.identity(n)\r\n",
        "    A=X.transpose().dot(X)+lmda_mat\r\n",
        "    W = np.linalg.solve(A,b)\r\n",
        "\r\n",
        "    return W\r\n",
        "\r\n",
        "lmda = 0.1\r\n",
        "W_ridge = ridge(xtrain, ytrain, lmda)\r\n",
        "print(\"W_ridge:\", W_ridge)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_ridge: [ 1.00606862e+02 -2.34634212e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oyzimeBZTyW"
      },
      "source": [
        "Create the following plots:\r\n",
        "* a scatter plot of the training data overlayed by the ridge solution\r\n",
        "* a scatter plot of the testing data overlayed by the ridge solution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtrPo_25ZQoP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "b02262ad-818a-421b-e547-d224bba48382"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "plt.scatter(xtrain[:,0],ytrain,marker='o')\r\n",
        "plt.plot(xtrain, W_ridge[0]*xtrain+W_ridge[1], 'b')\r\n",
        "plt.scatter(xtest[:,0],ytest,marker='+')\r\n",
        "plt.plot(xtest,W_ridge[0]*xtest+W_ridge[1],'r')\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1809f2feb8>,\n",
              " <matplotlib.lines.Line2D at 0x7f1809f3c7f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ_SS8CqbE6J"
      },
      "source": [
        "Compute training loss and testing loss using the *get_ridge_loss* function you have previously defined "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbBFX7qgaUG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "33f7b96f-5f15-4036-b1ad-05983d6d82c4"
      },
      "source": [
        "loss_train = get_ridge_loss(xtrain,ytrain,W_ridge,lmda)\r\n",
        "loss_test = get_ridge_loss(xtest,ytest,W_ridge,lmda)\r\n",
        "\r\n",
        "print(\"Training Loss:\", loss_train)\r\n",
        "print(\"Testing Loss:\", loss_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 1948.4269558238407\n",
            "Testing Loss: 1416.4284587303882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5sRIf0ejGKc"
      },
      "source": [
        "### Verifying Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlshXIRUkroc"
      },
      "source": [
        "Use sklearn's pre-built OLS model on our dataset and verify that your implementation matches its result\r\n",
        "\r\n",
        "Do this by printing $w_{ols}$ from your implementation and sklearn's implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ZnXuW2jLZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ff721cab-326d-4553-cbce-345a1666298f"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\r\n",
        "\r\n",
        "# Previous result\r\n",
        "W_ols = OLS(xtrain, ytrain)\r\n",
        "print(\"W_ols:\", W_ols)\r\n",
        "\r\n",
        "# Sklearn result\r\n",
        "W_ols_sklearn = LinearRegression().fit(xtrain,ytrain)\r\n",
        "\r\n",
        "print(\"W_ols_sklearn\", W_ols_sklearn.coef_[:-1], W_ols_sklearn.intercept_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_ols: [ 1.01054998e+02 -8.83448668e-02]\n",
            "W_ols_sklearn [101.05499781] -0.08834486680807707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRsvB1ok8oD"
      },
      "source": [
        "Use scklearn's pre-built Ridge model on our dataset and verify that your implementation matches its result.\r\n",
        "\r\n",
        "Use the same $\\lambda = 0.1$ from the previous section\r\n",
        "\r\n",
        "Do this by printing $w_{ridge}$ from your implementation and sklearn's implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl0_yDasjnZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0c281272-5ef7-4c16-a841-6dd88665d59a"
      },
      "source": [
        "from sklearn.linear_model import Ridge\r\n",
        "\r\n",
        "# Previous result\r\n",
        "W_ridge = ridge(xtrain, ytrain, lmda)\r\n",
        "print(\"W_ridge:\", W_ridge)\r\n",
        "\r\n",
        "# Sklearn result\r\n",
        "W_ridge_sklearn = Ridge(alpha=lmda).fit(xtrain,ytrain)\r\n",
        "\r\n",
        "print(\"W_ridge_sklearn\", W_ridge_sklearn.coef_[:-1], W_ridge_sklearn.intercept_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_ridge: [ 1.00606862e+02 -2.34634212e-02]\n",
            "W_ridge_sklearn [100.60687668] -0.02354380831199343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hEmdrNqb7x7"
      },
      "source": [
        "## **Question 4:** Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_G2AH4mcJpO"
      },
      "source": [
        "Throughout this question, we will be interested in tuning the hyper parameter $\\lambda$ in ridge regression. And showing ridge's impact vs regular OLS.\r\n",
        "\r\n",
        "To do this, we will need a more complex dataset. One which has many redundant, non-informative dimensions. So we will be defining a new synthetic dataset using the code below.\r\n",
        "\r\n",
        "Our dataset will have 50 samples, and 1000 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9roTCuaffTC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7024d34d-8fc4-4a5d-dc24-f4774ff4a67b"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "\r\n",
        "X, y, coefficients = make_regression(\r\n",
        "    n_samples=50,\r\n",
        "    n_features=1000,\r\n",
        "    n_informative=2,\r\n",
        "    n_targets=1,\r\n",
        "    noise=5,\r\n",
        "    coef=True,\r\n",
        "    random_state=10\r\n",
        ")\r\n",
        "y = abs(y)\r\n",
        "print(\"X shape:\", X.shape, sep='\\t')\r\n",
        "print(\"y shape:\", y.shape, sep='\\t')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:\t(50, 1000)\n",
            "y shape:\t(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB8jOiTSeRPs"
      },
      "source": [
        "Attach a vector of ones onto **X** to account for the bias value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0qc5igrdn4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "943076dd-a8f4-448a-f6ed-5b3284b29f40"
      },
      "source": [
        "ones = np.ones((50,1))\r\n",
        "print(ones.shape)\r\n",
        "X = np.hstack((X,ones))\r\n",
        "\r\n",
        "print(\"X shape:\", X.shape, sep='\\t')\r\n",
        "print(\"y shape:\", y.shape, sep='\\t')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1)\n",
            "X shape:\t(50, 1001)\n",
            "y shape:\t(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMEqFbP2eZZ2"
      },
      "source": [
        "Using **train_test_split** from sklearn, separate the data using a 60, 20, 20 split.\r\n",
        "\r\n",
        "* Make sure to suffle the dataset using a **random_state** of 42\r\n",
        "\r\n",
        "**Hint:** \r\n",
        "\r\n",
        "* This can be done easily with 2 calls to **train_test_split**. \r\n",
        "\r\n",
        "* The first call will split the data into train/test, and the second will split the train data into train/val\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1kbvkRZn-d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e482e4d2-eaa1-4d3f-f03a-3be6544b4d39"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size=0.2,random_state=42)\r\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain,test_size=0.25,random_state=42)\r\n",
        "\r\n",
        "print(\"xtrain shape:\", xtrain.shape, sep='\\t')\r\n",
        "print(\"xval shape:\", xval.shape, sep='\\t')\r\n",
        "print(\"xtest shape:\", xtest.shape, '\\n', sep='\\t')\r\n",
        "\r\n",
        "print(\"ytrain shape:\", ytrain.shape, sep='\\t')\r\n",
        "print(\"yval shape:\", yval.shape, sep='\\t')\r\n",
        "print(\"ytest shape:\", ytest.shape, sep='\\t')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain shape:\t(30, 1001)\n",
            "xval shape:\t(10, 1001)\n",
            "xtest shape:\t(10, 1001)\t\n",
            "\n",
            "ytrain shape:\t(30,)\n",
            "yval shape:\t(10,)\n",
            "ytest shape:\t(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gc1HKmCfU5b"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmPvDCxejAr"
      },
      "source": [
        "Using your implementation from the previous question,\r\n",
        "get the OLS solution on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTTXNGCJetfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9a625574-5186-465b-c4fe-989cb36be96e"
      },
      "source": [
        "W_ols = OLS(xtrain,ytrain)\r\n",
        "print(\"W_ols:\", W_ols[:10])    # For the sake of cleanliness we will only print first 10 coefficients"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_ols: [ -13.26861093  298.01003142 -127.44260886  106.46641054  303.01110206\n",
            " -131.63697552   80.12829674 -289.14061156 -444.02100392  -72.2118103 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATeeqIUmeyaF"
      },
      "source": [
        "Using your loss function from the previous question, obtain the train, val, and test losses of OLS.\r\n",
        "\r\n",
        "Is this solution over fitting the data? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7_ljfseeu2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f7dd44c3-b473-4a6c-e286-03c55d8665f4"
      },
      "source": [
        "loss_train = get_loss(xtrain,ytrain,W_ols)\r\n",
        "loss_val = get_loss(xval,yval,W_ols)\r\n",
        "loss_test = get_loss(xtest,ytest,W_ols)\r\n",
        "\r\n",
        "print(\"Training Loss:\", loss_train)\r\n",
        "print(\"Validation Loss:\", loss_val)\r\n",
        "print(\"Testing Loss:\", loss_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 2.785109936337628e-22\n",
            "Validation Loss: 146750236.1521715\n",
            "Testing Loss: 168834610.83436024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DgKGD-yfD5l"
      },
      "source": [
        "**Answer:\r\n",
        "The solution is DEFINITELY overfitting the data because the training loss is virtually zero while the validation and test loss is huge. That means that the solution must be too heavily tailored to the training data (i.e. it must be overfitting).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGljVyVpfXFs"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOCRHgVxdws6"
      },
      "source": [
        "Using your implementation from the previous question, and your validations data, tune the $\\lambda$ parameter of ridge regression. \r\n",
        "\r\n",
        "Do this by creating a loop that varies $\\lambda$ from 10e-20 to 10e-1 in factors of 10.\r\n",
        "\r\n",
        "On each iteration \r\n",
        "* calculate W_ridge using your previous implementation\r\n",
        "* calculate training and validation loss\r\n",
        "* store the training loss, validation loss, and $\\lambda$ value. These will be needed for the coming plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnyO-M6gADb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5e3938ab-2389-425d-9ea8-cf3b25c5005c"
      },
      "source": [
        "train_loss_arr = []\r\n",
        "val_loss_arr = []\r\n",
        "lmdas = []\r\n",
        "new_lmda = 10E-20\r\n",
        "\r\n",
        "for i in range(0, 20):\r\n",
        "     lmdas.append(new_lmda)\r\n",
        "     new_lmda=new_lmda*10\r\n",
        "     W_ridge = ridge(xtrain, ytrain, new_lmda)\r\n",
        "     loss_train = get_ridge_loss(xtrain,ytrain,W_ridge,new_lmda)\r\n",
        "     train_loss_arr.append(loss_train)\r\n",
        "     loss_val = get_ridge_loss(xval,yval,W_ridge,new_lmda)\r\n",
        "     val_loss_arr.append(loss_val)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Sanity checks\r\n",
        "print(lmdas)\r\n",
        "print(len(lmdas))\r\n",
        "print(train_loss_arr)\r\n",
        "print(len(train_loss_arr))\r\n",
        "print(val_loss_arr)\r\n",
        "print(len(val_loss_arr))\r\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1e-19, 1e-18, 1e-17, 1.0000000000000001e-16, 1e-15, 1.0000000000000002e-14, 1.0000000000000002e-13, 1.0000000000000002e-12, 1.0000000000000001e-11, 1.0000000000000002e-10, 1.0000000000000003e-09, 1.0000000000000004e-08, 1.0000000000000004e-07, 1.0000000000000004e-06, 1.0000000000000004e-05, 0.00010000000000000005, 0.0010000000000000005, 0.010000000000000005, 0.10000000000000006, 1.0000000000000007]\n",
            "20\n",
            "[1.0533485557230797e-11, 1.0533485556980137e-10, 1.053348555695507e-09, 6.044335279200504e-08, 2.9578416605740337e-09, 2.942732413838065e-07, 2.3321201452148604e-10, 2.2128001305728027e-09, 2.2115113523430577e-08, 2.2115007608885582e-07, 2.2115006366576263e-06, 2.21150063528761e-05, 0.0002211500633260262, 0.0022115006131064804, 0.022115004115698295, 0.22114983962054277, 2.211478242771093, 22.11276729392674, 220.92636898240616, 2189.34046323194]\n",
            "20\n",
            "[146750236.1521715, 146750236.1521715, 146750236.1521715, 746752601.2816122, 3330255.6962918127, 17192248.35305938, 187972.94765532447, 188102.04359809944, 187827.87728335694, 187826.4835818343, 187833.14705679877, 187833.13446040358, 187833.14365103893, 187833.14510472777, 187833.1622751143, 187833.3373924219, 187835.08860350845, 187852.59702236584, 188027.31305942032, 189738.23798628605]\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkv3n1yaebyS"
      },
      "source": [
        "Create a plot of the losses as a function of lamda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "jYK_NqPIgYjX",
        "outputId": "e97040e6-ee22-431f-8cb5-48d0702c0615"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "plt.plot(lmdas,train_loss_arr,label='train',color='r')\r\n",
        "plt.plot(lmdas,val_loss_arr,label='val',color='b')\r\n",
        "plt.xlabel('Lambda')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend([\"train\",\"val\"])\r\n",
        "plt.xlim(10E-20,10E-3)\r\n",
        "array=[10E-18, 10E-15, 10E-12, 10E-9, 10E-6, 10E-3]\r\n",
        "plt.xticks(array)\r\n",
        "plt.xscale('log')\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZOu07Wpgxl2"
      },
      "source": [
        "Identify the best lambda $\\lambda^*$, and train your final classifier $W^*_{ridge}$ on both the training and the validation data together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZNC6XEfhYTmq",
        "outputId": "baf8c8ff-5168-47a9-e0bb-ceb65edf92a3"
      },
      "source": [
        "# Identifying lambda_star\r\n",
        "#The value of lambda is the one that minimizes val_loss_arr, but has train_loss_array around one i.e. 10E-3\r\n",
        "#literally checked this using plug and chug later\r\n",
        "lmda_star = 10e-3\r\n",
        "\r\n",
        "# Creating final xtrain and ytrain\r\n",
        "xtrain_final = np.concatenate((xtrain,xval),axis=0)\r\n",
        "ytrain_final = np.concatenate((ytrain,yval),axis=0)\r\n",
        "print(xtrain_final.shape,ytrain_final.shape)\r\n",
        "# Calculating W_ridge_star\r\n",
        "W_ridge_star = ridge(xtrain_final,ytrain_final,lmda_star)\r\n",
        "\r\n",
        "print(\"lmda_star:\", lmda_star)\r\n",
        "print(\"W_ridge_star:\", W_ridge_star[:10]) # For the sake of cleanliness we will only print first 10 coefficients"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 1001) (40,)\n",
            "lmda_star: 0.01\n",
            "W_ridge_star: [ 0.36653702 -0.56248098  1.71947303 -0.51838903  0.60805999 -0.43737682\n",
            " -0.8218014   0.033005    0.88511027 -0.95337264]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4NkOKPphlZV"
      },
      "source": [
        "Using your loss function *get_ridge_loss* from the previous question, obtain the train, val, and test losses of $W_{ridge}^*$. Then answer the following questions:\r\n",
        "* Are we overfitting the dataset? Explain.\r\n",
        "* How are we performing compared to OLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lAcKos3phh89",
        "outputId": "ee06e746-2fee-4147-e922-00ae331e6466"
      },
      "source": [
        "loss_train = get_ridge_loss(xtrain,ytrain,W_ridge_star,lmda_star)\r\n",
        "loss_val = get_ridge_loss(xval,yval,W_ridge_star,lmda_star)\r\n",
        "loss_test = get_ridge_loss(xtest,ytest,W_ridge_star,lmda_star)\r\n",
        "\r\n",
        "print(\"Training Loss:\", loss_train)\r\n",
        "print(\"Validation Loss:\", loss_val)\r\n",
        "print(\"Testing Loss:\", loss_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 4.175775079514492\n",
            "Validation Loss: 4.175770352348638\n",
            "Testing Loss: 82376.2055939743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD3KrymEiNr1"
      },
      "source": [
        "**Answer:\r\n",
        "I still believe that the data is being overfitted. Even though validation loss is now very low in addition to training, the test loss is still much higher. This is still WAY better than the OLS solution because the OLS solution had test loss on the order of $10^8$ and this has test loss on the order of $10^4$.** "
      ]
    }
  ]
}